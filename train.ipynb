{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFFhUsGu0DFo",
        "colab_type": "text"
      },
      "source": [
        "This is the code for model training.There are 3 important functions here\n",
        "\n",
        "1) init() : It returns the config dictionary from the task/pose.py,whcih stores values of all the necessary parameters required during the training of the model.\n",
        "\n",
        "2)train() : resposible for the training of the model.\n",
        "\n",
        "3) main() : calls the functions init() and train() \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6RiV4P-WUSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "from os.path import dirname\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True\n",
        "cudnn.enabled = True\n",
        "import torch\n",
        "import importlib\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "from pytz import timezone"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft8i5EnjWj5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_command_line():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-c', '--continue_exp', type=str, help='continue exp')\n",
        "    parser.add_argument('-e', '--exp', type=str, default='pose', help='experiments name')\n",
        "    parser.add_argument('-m', '--max_iters', type=int, default=250, help='max number of iterations (thousands)')\n",
        "    args = parser.parse_args()\n",
        "    return args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeClvI3vWq1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pt'):\n",
        "    \"\"\"\n",
        "    from pytorch/examples\n",
        "    \"\"\"\n",
        "    basename = dirname(filename)\n",
        "    if not os.path.exists(basename):\n",
        "        os.makedirs(basename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l-mvsMxWud1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save(config):\n",
        "    resume = os.path.join('exp', config['opt'].exp)\n",
        "    if config['opt'].exp=='pose' and config['opt'].continue_exp is not None:\n",
        "        resume = os.path.join('exp', config['opt'].continue_exp)\n",
        "    resume_file = os.path.join(resume, 'checkpoint.pt')\n",
        "\n",
        "    save_checkpoint({\n",
        "            'state_dict': config['inference']['net'].state_dict(),\n",
        "            'optimizer' : config['train']['optimizer'].state_dict(),\n",
        "            'epoch': config['train']['epoch'],\n",
        "        }, False, filename=resume_file)\n",
        "    print('=> save checkpoint')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bJivwQeWxvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_func, data_func, config, post_epoch=None):\n",
        "    while True:\n",
        "        fails = 0\n",
        "        print('epoch: ', config['train']['epoch'])\n",
        "        if 'epoch_num' in config['train']:\n",
        "            if config['train']['epoch'] > config['train']['epoch_num']:\n",
        "                break\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            num_step = config['train']['{}_iters'.format(phase)]\n",
        "            generator = data_func(phase)\n",
        "            print('start', phase, config['opt'].exp)\n",
        "\n",
        "            show_range = range(num_step)\n",
        "            show_range = tqdm.tqdm(show_range, total = num_step, ascii=True)\n",
        "            batch_id = num_step * config['train']['epoch']\n",
        "            if batch_id > config['opt'].max_iters * 1000:\n",
        "                return\n",
        "            for i in show_range:\n",
        "                datas = next(generator)\n",
        "                outs = train_func(batch_id + i, config, phase, **datas)\n",
        "        config['train']['epoch'] += 1\n",
        "        save(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA2aeB1MlW0n",
        "colab_type": "text"
      },
      "source": [
        "The function given below does the followning 2 things\n",
        "1)exports the config dictionary from task/pose.py, which  contains all  the necessary variables for training and return this library in the variable \"config\"\n",
        "2)It exports the training function \"make_network\",also saved in tasks/pose.py\n",
        "and returns it in the variable func. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEC2NtlwW2GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init():\n",
        "    \"\"\"\n",
        "    task.__config__ contains the variables that control the training and testing\n",
        "    make_network (which is a function in task/pose.py) builds a function which can do forward and backward propagation\n",
        "    \"\"\"\n",
        "    opt = parse_command_line()\n",
        "    task = importlib.import_module('task.pose')\n",
        "    exp_path = os.path.join('exp', opt.exp)\n",
        "    \n",
        "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "    config = task.__config__   #here all variables related to training the model,which were defined in task.pose are put in this variable\n",
        "    try: os.makedirs(exp_path)\n",
        "    except FileExistsError: pass\n",
        "\n",
        "    config['opt'] = opt\n",
        "    config['data_provider'] = importlib.import_module(config['data_provider']) #this imports the MP2 dataset in the 'data_provider'  attribute of config\n",
        "\n",
        "    func = task.make_network(config)\n",
        "    reload(config)\n",
        "    return func, config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GwUaxIpW6Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    func, config = init()\n",
        "    data_func = config['data_provider'].init(config)\n",
        "    train(func, data_func, config)\n",
        "    print(datetime.now(timezone('EST')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPHklTC1W_Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEUXBFAse2bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}