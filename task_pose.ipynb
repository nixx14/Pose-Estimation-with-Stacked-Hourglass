{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_pose.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sab9dBjbhX7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import os\n",
        "from torch.nn import DataParallel\n",
        "from utils.misc import make_input, make_output, importNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN5EP9M1Wd-i",
        "colab_type": "text"
      },
      "source": [
        "__config__ contains the options for training and testing\n",
        "Basically all of the variables related to training are put in __config__['train']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRZ4Bgmdhp5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__config__ = {\n",
        "    'data_provider': 'data.MPII.dp',\n",
        "    'network': 'models.posenet.PoseNet',\n",
        "    'inference': {\n",
        "        'nstack': 8,\n",
        "        'inp_dim': 256,\n",
        "        'oup_dim': 16,\n",
        "        'num_parts': 16,\n",
        "        'increase': 0,\n",
        "        'keys': ['imgs'],\n",
        "        'num_eval': 2958, ## number of val examples used. entire set is 2958\n",
        "        'train_num_eval': 300, ## number of train examples tested at test time\n",
        "    },\n",
        "\n",
        "    'train': {\n",
        "        'batchsize': 16,\n",
        "        'input_res': 256,\n",
        "        'output_res': 64,\n",
        "        'train_iters': 1000,\n",
        "        'valid_iters': 10,\n",
        "        'learning_rate': 1e-3,\n",
        "        'max_num_people' : 1,\n",
        "        'loss': [\n",
        "            ['combined_hm_loss', 1],\n",
        "        ],\n",
        "        'decay_iters': 100000,\n",
        "        'decay_lr': 2e-4,\n",
        "        'num_workers': 2,\n",
        "        'use_data_loader': True,\n",
        "    },\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTp-f-Pghq__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer(nn.Module):\n",
        "    \"\"\"\n",
        "    The wrapper module that will behave differetly for training or testing\n",
        "    inference_keys specify the inputs for inference\n",
        "    \"\"\"\n",
        "    def __init__(self, model, inference_keys, calc_loss=None):\n",
        "        super(Trainer, self).__init__()\n",
        "        self.model = model\n",
        "        self.keys = inference_keys\n",
        "        self.calc_loss = calc_loss\n",
        "\n",
        "    def forward(self, imgs, **inputs):\n",
        "        inps = {}\n",
        "        labels = {}\n",
        "\n",
        "        for i in inputs:\n",
        "            if i in self.keys:\n",
        "                inps[i] = inputs[i]\n",
        "            else:\n",
        "                labels[i] = inputs[i]\n",
        "\n",
        "        if not self.training:\n",
        "            return self.model(imgs, **inps)\n",
        "        else:\n",
        "            combined_hm_preds = self.model(imgs, **inps)\n",
        "            if type(combined_hm_preds)!=list and type(combined_hm_preds)!=tuple:\n",
        "                combined_hm_preds = [combined_hm_preds]\n",
        "            loss = self.calc_loss(**labels, combined_hm_preds=combined_hm_preds)\n",
        "            return list(combined_hm_preds) + list([loss])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wJxRzZkPNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_network(configs):\n",
        "    train_cfg = configs['train']\n",
        "    config = configs['inference']\n",
        "\n",
        "    def calc_loss(*args, **kwargs):\n",
        "        return poseNet.calc_loss(*args, **kwargs)\n",
        "    \n",
        "    ## creating new posenet\n",
        "    PoseNet = importNet(configs['network'])\n",
        "    poseNet = PoseNet(**config)\n",
        "    forward_net = DataParallel(poseNet.cuda())\n",
        "    config['net'] = Trainer(forward_net, configs['inference']['keys'], calc_loss)\n",
        "    \n",
        "    ## optimizer, experiment setup\n",
        "    train_cfg['optimizer'] = torch.optim.Adam(filter(lambda p: p.requires_grad,config['net'].parameters()), train_cfg['learning_rate'])\n",
        "\n",
        "    exp_path = os.path.join('exp', configs['opt'].exp)\n",
        "    if configs['opt'].exp=='pose' and configs['opt'].continue_exp is not None:\n",
        "        exp_path = os.path.join('exp', configs['opt'].continue_exp)\n",
        "    if not os.path.exists(exp_path):\n",
        "        os.mkdir(exp_path)\n",
        "    logger = open(os.path.join(exp_path, 'log'), 'a+')\n",
        "\n",
        "    def make_train(batch_id, config, phase, **inputs):\n",
        "        for i in inputs:\n",
        "            try:\n",
        "                inputs[i] = make_input(inputs[i])\n",
        "            except:\n",
        "                pass #for last input, which is a string (id_)\n",
        "                \n",
        "        net = config['inference']['net']\n",
        "        config['batch_id'] = batch_id\n",
        "\n",
        "        net = net.train()\n",
        "\n",
        "        if phase != 'inference':\n",
        "            result = net(inputs['imgs'], **{i:inputs[i] for i in inputs if i!='imgs'})\n",
        "            num_loss = len(config['train']['loss'])\n",
        "\n",
        "            losses = {i[0]: result[-num_loss + idx]*i[1] for idx, i in enumerate(config['train']['loss'])}\n",
        "                        \n",
        "            loss = 0\n",
        "            toprint = '\\n{}: '.format(batch_id)\n",
        "            for i in losses:\n",
        "                loss = loss + torch.mean(losses[i])\n",
        "\n",
        "                my_loss = make_output( losses[i] )\n",
        "                my_loss = my_loss.mean()\n",
        "\n",
        "                if my_loss.size == 1:\n",
        "                    toprint += ' {}: {}'.format(i, format(my_loss.mean(), '.8f'))\n",
        "                else:\n",
        "                    toprint += '\\n{}'.format(i)\n",
        "                    for j in my_loss:\n",
        "                        toprint += ' {}'.format(format(j.mean(), '.8f'))\n",
        "            logger.write(toprint)\n",
        "            logger.flush()\n",
        "            \n",
        "            if phase == 'train':\n",
        "                optimizer = train_cfg['optimizer']\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            if batch_id == config['train']['decay_iters']:\n",
        "                ## decrease the learning rate after decay # iterations\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = config['train']['decay_lr']\n",
        "            \n",
        "            return None\n",
        "        else:\n",
        "            out = {}\n",
        "            net = net.eval()\n",
        "            result = net(**inputs)\n",
        "            if type(result)!=list and type(result)!=tuple:\n",
        "                result = [result]\n",
        "            out['preds'] = [make_output(i) for i in result]\n",
        "            return out\n",
        "    return make_train"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}